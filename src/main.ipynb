{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of how to use puppy embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import paddle.v2 as paddle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from category_stage import squeezenet\n",
    "from siamese_stage import siamese, infer\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "\n",
    "# Initialize PaddlePaddle.\n",
    "paddle.init(use_gpu=False, trainer_count=1)\n",
    "\n",
    "DATA_DIM = 3 * 128 * 128\n",
    "CLASS_DIM = 120\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Define input layers\n",
    "image = paddle.layer.data(\n",
    "    name=\"image\", type=paddle.data_type.dense_vector(DATA_DIM))\n",
    "lbl = paddle.layer.data(\n",
    "    name=\"label\", type=paddle.data_type.integer_value(CLASS_DIM))\n",
    "\n",
    "# Configure the neural network.\n",
    "out, intermediate = squeezenet(image, CLASS_DIM, True, True)\n",
    "cost = paddle.layer.classification_cost(input=out, label=lbl)\n",
    "\n",
    "with gzip.open('/book/working/models/params_pass_47.tar.gz', 'r') as f:\n",
    "    parameters = paddle.parameters.Parameters.from_tar(f)\n",
    "    \n",
    "# Get data (or subsitute in your own!)\n",
    "file_list = [line.strip().split(\"\\t\")[0] for line in open(\"/book/working/data/val.list\")]\n",
    "test_data = [(paddle.image.load_and_transform(image_file, 128 + 64, 128, False)\n",
    "      .flatten().astype('float32'), )\n",
    "     for image_file in file_list]\n",
    "\n",
    "# Pseudo-batch data\n",
    "batches = []\n",
    "for i in range((len(test_data) / 100)):\n",
    "    batches.append(test_data[i:i+100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now lets load in our actual embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get intermediate embs from squeezenet\n",
    "intermediate_embs = []\n",
    "for batch in batches:\n",
    "    intermediate_embs += list(paddle.infer(\n",
    "        output_layer=intermediate,\n",
    "        parameters=parameters,\n",
    "        input=batch))\n",
    "\n",
    "# Get final embeddings from Siamese\n",
    "embs = infer.intermediate(np.array(intermediate_embs, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "Cool ways of using puppy embeddings. Most of these are analogous to word embedding operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity calculation\n",
    "\n",
    "One really easy way of calculating the similarity of two dog images is simply calculating the euclidian distance between their embeddings. First we find the distance between these two dogs:\n",
    "![title](/tree/working/data/Images/n02085620-Chihuahua/n02085620_2650.jpg)\n",
    "![title](/tree/working/data/Images/n02085620-Chihuahua/n02085620_2517.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/book/working/data/Images/n02085620-Chihuahua/n02085620_2650.jpg\n",
      "/book/working/data/Images/n02085620-Chihuahua/n02085620_2517.jpg\n",
      "0.10574257373809814\n"
     ]
    }
   ],
   "source": [
    "# Here, we compare two pictures of chihuahuas.\n",
    "print(file_list[0])\n",
    "print(file_list[5])\n",
    "# The distance between the chihuahuas is low: 0.1\n",
    "print(cosine(embs[0], embs[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance between those two dogs is very low: 0.105. This is because the dogs are similar.\n",
    "\n",
    "Now, let's find the distance between these two dogs\n",
    "![title](/tree/working/data/Images/n02085620-Chihuahua/n02085620_2517.jpg)\n",
    "![title](/tree/working/data/Images/n02085936-Maltese_dog/n02085936_13378.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/book/working/data/Images/n02085620-Chihuahua/n02085620_2517.jpg\n",
      "/book/working/data/Images/n02085936-Maltese_dog/n02085936_13378.jpg\n",
      "0.7161149084568024\n"
     ]
    }
   ],
   "source": [
    "# Here we compare a chihuahua and a maltese dog.\n",
    "print(file_list[5])\n",
    "print(file_list[209])\n",
    "# The distance between them is high: 0.7\n",
    "print(cosine(embs[5], embs[209]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance between these two dogs is much higher than last time: 0.7. This is because the rare puppers look different.\n",
    "\n",
    "# Puppy algebra\n",
    "\n",
    "Now, we can apply algebra to puppies. For example, we will add two puppy pictures to get a puppy that looks similar to both. Here, we will add these two dogs:\n",
    "![Dog #1](/tree/working/data/Images/n02085620-Chihuahua/n02085620_4919.jpg)\n",
    "![Dog #2](/tree/working/data/Images/n02091831-Saluki/n02091831_648.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/book/working/data/Images/n02085620-Chihuahua/n02085620_4919.jpg\n",
      "/book/working/data/Images/n02091831-Saluki/n02091831_648.jpg\n",
      "Best match: /book/working/data/Images/n02115913-dhole/n02115913_3991.jpg\n",
      "0.015775024890899658\n"
     ]
    }
   ],
   "source": [
    "# We print the dogs' picture path.\n",
    "print(file_list[1])\n",
    "print(file_list[2047])\n",
    "# We first add the two puppies embeddings together.\n",
    "vector = embs[1] + embs[2047]\n",
    "# We normalize the vector to norm1.\n",
    "vector = vector / np.linalg.norm(vector)\n",
    "\n",
    "# We find the closest image to the vector embedding.\n",
    "min_dist = 1\n",
    "best = None\n",
    "for i, emb in enumerate(embs):\n",
    "    if cosine(emb, vector) < min_dist:\n",
    "        best = (i, emb)\n",
    "        min_dist = cosine(emb, vector)\n",
    "\n",
    "# We print the resulting dog's picture path.\n",
    "print(\"Best match: \" + file_list[best[0]])\n",
    "# Print confidence score.\n",
    "print(min_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, the result of adding those two dogs gives us the dog at path `/book/working/data/Images/n02115913-dhole/n02115913_3991.jpg`. That path is this picture:\n",
    "![Dog #1 + Dog #2 =](/tree/working/data/Images/n02115913-dhole/n02115913_3991.jpg)\n",
    "It's got the ears and the mouth of the chihuahua, and the sleek and brown body of the maltese dog.\n",
    "Try this on other pairs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
